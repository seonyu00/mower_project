# /home/sy/ros2_ws/src/mower_ai/mower_ai/ai_controller_node.py
import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy
import numpy as np
import torch
import os
from ament_index_python.packages import get_package_share_directory
from nav_msgs.msg import Path
from geometry_msgs.msg import PoseStamped

# --- íŒŒì¼ ì„í¬íŠ¸ ---
from .rl.network import ActorCritic 
from .planning.cpp import CoveragePlanner, HeuristicType

# --- ROS ë©”ì‹œì§€ ---
from nav_msgs.msg import Odometry, OccupancyGrid
from geometry_msgs.msg import Twist, PoseStamped
from sensor_msgs.msg import LaserScan
# [í™•ì¸] ë¦¬ìŠ¤íŠ¸ ë©”ì‹œì§€ íƒ€ì… ì„í¬íŠ¸ í•„ìˆ˜
from mower_msgs.msg import DetectedObject, DetectedObjectList 
from tf2_ros import Buffer, TransformListener
from scipy.spatial.transform import Rotation as R

class AIParams:
    R_GOAL_M = 5.0
    R_OBJ_M = 5.0
    R_RAY_M = 6.0  
    T_CAP_S = 5.0
    VMAX_OBJ = 1.5
    RAY_COUNT = 64
    max_objs = 3
    
    GLOBAL_WIDTH_M = 20.0
    GLOBAL_HEIGHT_M = 20.0

    # ì‚¬ëŒ ê°ì§€ ê´€ë ¨ íŒŒë¼ë¯¸í„°
    HUMAN_CONFIRM_TIME = 0.5  # 0.5ì´ˆ ì´ìƒ ê°ì§€ë˜ì–´ì•¼ PPO ì§„ì…
    HUMAN_CLEAR_TIME = 3.0    # ì‚¬ëŒì´ ì‚¬ë¼ì§€ê³  3ì´ˆ ë’¤ì— ë³µê·€
    HUMAN_DETECT_DIST = 3.0   # 3m ì´ë‚´ì¼ ë•Œë§Œ ë°˜ì‘

    ACTION_MAP = {
        0: (0.5, 0.0),   # ì „ì§„
        1: (0.0, 0.8),   # ì¢ŒíšŒì „
        2: (-0.6, 0.0),  # í›„ì§„
        3: (0.0, -0.8),  # ìš°íšŒì „
        4: (0.0, 0.0),   # ì •ì§€
    }
    DANGER_M = 2.0 

class State:
    WAITING_FOR_MAP = 0 
    PLANNING = 1        
    EXECUTING = 2       
    FINISHED = 3        
    BACKING_UP = 4  
    WIGGLING = 5  
    PPO_HUMAN_AVOID = 6 # ì‚¬ëŒ íšŒí”¼ ëª¨ë“œ

class AiControllerNode(Node):
    def __init__(self):
        super().__init__('ai_controller_node')
        self.get_logger().info("AI Controller: Initializing...")
        
        self.declare_parameter('map_width', 20.0)
        self.declare_parameter('map_height', 20.0)
        self.current_state = State.WAITING_FOR_MAP
        self.params = AIParams()
        self.ppo_active_timer = 0
        
        # --- PPO ëª¨ë¸ ë¡œë“œ ---
        self.ppo_model = None
        try:
            self.ppo_model = ActorCritic(obs_dim=100, act_dim=5)
            package_dir = get_package_share_directory('mower_ai')
            model_path = os.path.join(package_dir, 'models', 'best_ever.pt')
            if os.path.exists(model_path):
                self.ppo_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
                self.ppo_model.eval()
                self.get_logger().info(f"PPO Loaded: {model_path}")
            else:
                self.get_logger().warn(f"Model not found at {model_path}. PPO will act random.")
        except Exception as e:
            self.get_logger().error(f"PPO Load Error: {e}")

        # --- ë°ì´í„° ë³€ìˆ˜ ---
        self.latest_scan_data = np.ones(self.params.RAY_COUNT, dtype=np.float32) * self.params.R_RAY_M
        self.current_pose_xy = np.array([0.0, 0.0])
        self.current_pose_yaw = 0.0
        self.latest_obstacle_data = None # ë‹¨ì¼ ê°ì²´ ì €ì¥ìš© (ê¸°ì¡´ ë¡œì§ í˜¸í™˜)
        self.latest_human_data = None

        self.visited_history = [] 
        self.last_record_pos = np.array([999.0, 999.0])

        self.current_linear_val = 0.0
        self.current_angular_val = 0.0

        self.steps_after_planning = 0
        self.backup_timer = 0
        self.last_wp_idx = -1
        self.wp_stuck_timer = 0

        self.planning_fail_count = 0
        
        # --- ì‚¬ëŒ ê°ì§€ íƒ€ì´ë¨¸ ---
        self.human_detect_timer = 0.0
        self.human_clear_timer = 0.0
        
        # --- ê²½ë¡œ ê´€ë ¨ ---
        self.global_path = [] 
        self.wp_idx = 0
        
        self.map_data = None
        self.map_info = None
        self.GRID_SIZE_M = 0.8 
        
        # ì•¡ì…˜ ë½(Lock)ì„ ìœ„í•œ íƒ€ì´ë¨¸ì™€ ì €ì¥ì†Œ
        self.action_lock_timer = 0  # ì´ ê°’ì´ 0ë³´ë‹¤ í¬ë©´ AI íŒë‹¨ì„ ìƒëµí•˜ê³  ì´ì „ í–‰ë™ ë°˜ë³µ
        self.locked_action = 4      # ì €ì¥ëœ í–‰ë™ (ê¸°ë³¸ ì •ì§€)

        # --- ROS í†µì‹  ---
        qos_map = QoSProfile(depth=1, reliability=ReliabilityPolicy.RELIABLE, durability=DurabilityPolicy.TRANSIENT_LOCAL)
        
        self.create_subscription(Odometry, '/odom', self.odom_callback, 10)
        self.create_subscription(LaserScan, '/scan', self.scan_callback, 10)
        self.create_subscription(OccupancyGrid, '/map', self.map_callback, qos_map)
 
        # ì¹´ë©”ë¼ ë°ì´í„°ë¥¼ ë°›ëŠ” êµ¬ë…(Subscription) ì¶”ê°€
        self.create_subscription(
            DetectedObjectList,          # ë¦¬ìŠ¤íŠ¸ íƒ€ì… ë©”ì‹œì§€
            '/detected_obstacle',        # Unityì™€ ë™ì¼í•œ í† í”½ ì´ë¦„
            self.human_detection_callback, # ì—°ê²°í•  ì½œë°± í•¨ìˆ˜
            10
        )
        
        self.cmd_vel_publisher = self.create_publisher(Twist, '/cmd_vel', 10)
        self.path_publisher = self.create_publisher(Path, '/mower_path', 10)
        
        self.create_timer(0.1, self.main_loop)
        
        self.get_logger().info("Waiting for /map topic...")

    def odom_callback(self, msg: Odometry):
        self.current_pose_xy[0] = msg.pose.pose.position.x
        self.current_pose_xy[1] = msg.pose.pose.position.y
        
        q = msg.pose.pose.orientation
        siny_cosp = 2 * (q.w * q.z + q.x * q.y)
        cosy_cosp = 1 - 2 * (q.y * q.y + q.z * q.z)
        self.current_pose_yaw = np.arctan2(siny_cosp, cosy_cosp)

    # ì‚¬ëŒ ê°ì§€ ì „ìš©ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    # ê¸°ì¡´ ì¥ì• ë¬¼ ë°ì´í„°(self.latest_obstacle_data) ì—…ë°ì´íŠ¸ëŠ” ì—¬ê¸°ì„œ í•˜ì§€ ì•Šê±°ë‚˜
    # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    def human_detection_callback(self, msgs):
        # [ë””ë²„ê¹…] ë°ì´í„° ìˆ˜ì‹  í™•ì¸ìš© ë¡œê·¸ (1ì´ˆì— í•œ ë²ˆë§Œ ì¶œë ¥)
        if len(msgs.objects) > 0:
            self.get_logger().info(f"Vision Recv: {len(msgs.objects)} objs", throttle_duration_sec=1.0)

        detected = False
        min_dist = 99.9
        
        # 1. ì‚¬ëŒ ê°ì§€ ì—¬ë¶€ íŒë‹¨ (íƒ€ì´ë¨¸ ì—…ë°ì´íŠ¸ìš©)
        for obj in msgs.objects:
            if obj.label == "person":
                if obj.distance < self.params.HUMAN_DETECT_DIST:
                    if abs(obj.angle) < 60.0:
                        detected = True
                        min_dist = min(min_dist, obj.distance)

        # 2. íƒ€ì´ë¨¸ ë¡œì§ ì—…ë°ì´íŠ¸
        if detected:
            self.human_detect_timer += 0.1 
            self.human_clear_timer = 0.0   
        else:
            self.human_detect_timer = 0.0  
            self.human_clear_timer += 0.1  
        
        # 3. ê¸°ì¡´ ì£¼í–‰ ë¡œì§ í˜¸í™˜ì„±ì„ ìœ„í•´ ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ í•˜ë‚˜ë¥¼ ì €ì¥ 
        #  ê°ì§€ëœ ê²½ìš°, ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ëŒ ì •ë³´ë¥¼ 'ì „ìš© ë³€ìˆ˜'ì— ì €ì¥
        if len(msgs.objects) > 0:
             # ì‚¬ëŒ ë¼ë²¨ì¸ ê²ƒ ì¤‘ ê°€ì¥ ê°€ê¹Œìš´ ê²ƒ ì°¾ê¸°
             people = [obj for obj in msgs.objects if obj.label == "person"]
             if people:
                 self.latest_human_data = min(people, key=lambda x: x.distance)
             else:
                 self.latest_human_data = None
        else:
             self.latest_human_data = None

    def scan_callback(self, msg: LaserScan):
        if len(msg.ranges) == 0: return
        raw = np.array(msg.ranges, dtype=np.float32)
        raw[np.isinf(raw)] = self.params.R_RAY_M
        raw = np.clip(raw, 0.0, self.params.R_RAY_M)
        if len(raw) == self.params.RAY_COUNT:
            self.latest_scan_data = raw
        else:
            indices = np.linspace(0, len(raw)-1, self.params.RAY_COUNT).astype(int)
            self.latest_scan_data = raw[indices]

    def map_callback(self, msg: OccupancyGrid):
        if msg.info.width == 0 or msg.info.height == 0: return
        self.map_data = msg.data
        self.map_info = msg.info
        if self.current_state == State.WAITING_FOR_MAP:
            self.get_logger().info(f"Initial Map Received! Size: {msg.info.width}x{msg.info.height}")
            self.current_state = State.PLANNING

    def generate_path_from_map(self):
        self.get_logger().info("Start Path Planning...")
        if self.map_info is None:
            self.get_logger().warn("No Map Info yet.")
            return False
        
        slam_res = self.map_info.resolution
        slam_w = self.map_info.width
        slam_h = self.map_info.height
        slam_ox = self.map_info.origin.position.x
        slam_oy = self.map_info.origin.position.y
        
        raw_map = np.array(self.map_data).reshape(slam_h, slam_w)
        global_w = self.get_parameter('map_width').value
        global_h = self.get_parameter('map_height').value
        grid_res = self.GRID_SIZE_M 
        
        # ì•ˆì „í•œ ì‹œì‘ì  ì„¤ì • (ë²½ ë¼ì„ ë°©ì§€)
        fixed_ox = 0.0  
        fixed_oy = -20.0 
        
        new_w = int(global_w / grid_res)
        new_h = int(global_h / grid_res)
        
        planner_grid = np.zeros((new_h, new_w), dtype=int)
        
        # í…Œë‘ë¦¬ ë²½ ì„¤ì •
        planner_grid[0, :] = 1
        planner_grid[-1, :] = 1
        planner_grid[:, 0] = 1
        planner_grid[:, -1] = 1

        for r in range(new_h):
            for c in range(new_w):
                cell_min_x = fixed_ox + (c * grid_res)
                cell_max_x = cell_min_x + grid_res
                cell_min_y = fixed_oy + (r * grid_res)
                cell_max_y = cell_min_y + grid_res
                
                slam_c_min = int((cell_min_x - slam_ox) / slam_res)
                slam_c_max = int((cell_max_x - slam_ox) / slam_res)
                slam_r_min = int((cell_min_y - slam_oy) / slam_res)
                slam_r_max = int((cell_max_y - slam_oy) / slam_res)
                
                slam_c_min = max(0, slam_c_min); slam_c_max = min(slam_w, slam_c_max)
                slam_r_min = max(0, slam_r_min); slam_r_max = min(slam_h, slam_r_max)
                
                if slam_c_min >= slam_c_max or slam_r_min >= slam_r_max: continue
                
                chunk = raw_map[slam_r_min:slam_r_max, slam_c_min:slam_c_max]
                obstacle_count = np.count_nonzero(chunk > 50)
                
                if obstacle_count > 12:
                    planner_grid[r, c] = 1

        start_c = int((self.current_pose_xy[0] - fixed_ox) / grid_res)
        start_r = int((self.current_pose_xy[1] - fixed_oy) / grid_res)
        start_c = np.clip(start_c, 0, new_w-1)
        start_r = np.clip(start_r, 0, new_h-1)

        if planner_grid[start_r, start_c] == 1:
            self.get_logger().warn("Start pos in Obstacle! Searching nearby...")
            found_free = False
            search_range = 3  
            for r_off in range(-search_range, search_range + 1):
                for c_off in range(-search_range, search_range + 1):
                    nr, nc = start_r + r_off, start_c + c_off
                    if 0 <= nr < new_h and 0 <= nc < new_w and planner_grid[nr, nc] == 0:
                        start_r, start_c = nr, nc
                        found_free = True
                        break
                if found_free: break
            
            if found_free:
                self.get_logger().info(f"Moved Start to: ({start_r}, {start_c})")
            else:
                self.get_logger().error("CRITICAL: Stuck in walls!")
                return False

        # [ê°•ì œ ì´ˆê¸°í™”] ì‹œì‘ì ì€ ë¬´ì¡°ê±´ ë¹ˆ ê³µê°„ìœ¼ë¡œ ì„¤ì •
        if 0 <= start_r < new_h and 0 <= start_c < new_w:
            planner_grid[start_r, start_c] = 0 
            self.get_logger().info(f"Forced Start Node ({start_r}, {start_c}) to be FREE.")

        try:
            planner = CoveragePlanner(planner_grid)
            planner.start(initial_orientation=0)
            planner.current_pos = [start_r, start_c, 0]

            visited_mask = np.zeros((new_h, new_w), dtype=bool)
            for pos in self.visited_history:
                vc = int((pos[0] - fixed_ox) / grid_res) 
                vr = int((pos[1] - fixed_oy) / grid_res)
                if 0 <= vr < new_h and 0 <= vc < new_w:
                    visited_mask[vr, vc] = True
            
            visited_mask[start_r, start_c] = False 
            planner.visited = visited_mask
            
            planner.compute()
            result = planner.result() 
            
            if not result[0] or len(result[4]) == 0:
                self.get_logger().error("Planning Failed! No path found")
                return False
            
            path_indices = result[4] 
            self.global_path = []
            for (r, c) in path_indices:
                wx = (c * grid_res) + fixed_ox + (grid_res/2)
                wy = (r * grid_res) + fixed_oy + (grid_res/2)
                self.global_path.append([float(wx), float(wy)])

            self.get_logger().info(f"Global Path Generated! Points: {len(self.global_path)}")
            self.publish_path()
            
            if not self.global_path: return False
            
            self.wp_idx = min(3, len(self.global_path) - 1)
            self.steps_after_planning = 0
            self.wp_stuck_timer = 0
            self.last_wp_idx = -1
            return True
        except Exception as e:
            self.get_logger().error(f"Planner Error: {e}")
            return False

    def build_state_for_ppo(self):

        # PPO ëª¨ë“œì¼ ë•ŒëŠ” ëª©í‘œì (Target)ì„ ë‚´ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì‹¤ì‹œê°„ ê°±ì‹ í•´ì•¼ í•¨
        # ê·¸ë˜ì•¼ ì‚¬ëŒì„ í”¼í•˜ë©´ì„œë„ 'ê²½ë¡œ ìª½ìœ¼ë¡œ' ì›€ì§ì´ë ¤ê³  ë…¸ë ¥í•¨
        
        current_target_idx = self.wp_idx

        # ë§Œì•½ PPO ëª¨ë“œì´ê³ , ê¸°ì¡´ ê²½ë¡œê°€ ë‚¨ì•„ìˆë‹¤ë©´?
        if self.current_state == State.PPO_HUMAN_AVOID and self.global_path:
            #  ë‚´ í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ê²½ë¡œì  ì°¾ê¸° (ìˆ˜í•™ì  ê³„ì‚°)
            path_arr = np.array(self.global_path)
            dists = np.linalg.norm(path_arr - self.current_pose_xy, axis=1)
            nearest_idx = np.argmin(dists)
            
            # ê·¸ ì ë³´ë‹¤ ì¡°ê¸ˆ ì•(Look Ahead)ì„ ëª©í‘œë¡œ ì„¤ì •
            # ë„ˆë¬´ ê°€ê¹Œìš´ ì ì„ ì°ìœ¼ë©´ ì œìë¦¬ì—ì„œ ë”, 3~5ì¹¸ ì•ì„ ë³´ê²Œ í•¨
            look_ahead_step = 5 
            current_target_idx = min(nearest_idx + look_ahead_step, len(self.global_path) - 1)
            
            #  ë””ë²„ê¹… AIê°€ ì–´ë””ë¥¼ ëª©í‘œë¡œ ì‚¼ì•˜ëŠ”ì§€ ì¶œë ¥
            self.get_logger().info(f"PPO Dynamic Target: WP {current_target_idx}", throttle_duration_sec=2.0)

        # 1. Goal Info (3)
        target = self.global_path[current_target_idx] if current_target_idx < len(self.global_path) else self.global_path[-1]
        dx = target[0] - self.current_pose_xy[0]
        dy = target[1] - self.current_pose_xy[1]
        dist = np.hypot(dx, dy)
        angle = np.arctan2(dy, dx) - self.current_pose_yaw
        
        # ê°ë„ ì •ê·œí™” (-PI ~ PI)
        while angle > np.pi: angle -= 2 * np.pi
        while angle < -np.pi: angle += 2 * np.pi
        
        goal_feats = [min(dist, self.params.R_GOAL_M) / self.params.R_GOAL_M, 
                      np.cos(angle), 
                      np.sin(angle)
                    ]
        # 2. Obstacle Info (15)
        obj_feats = []
        # [ë…¼ë¦¬ì  ìˆ˜ì •] ëª¨ë“œì— ë”°ë¼ AIì—ê²Œ ì£¼ì…í•  ë°ì´í„°ë¥¼ ê²°ì •
        target_obs = None
        if self.current_state == State.PPO_HUMAN_AVOID:
            # ì‚¬ëŒ íšŒí”¼ ëª¨ë“œë©´ -> ì¹´ë©”ë¼ ë°ì´í„°(human_data)ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©
            if self.latest_human_data:
                target_obs = self.latest_human_data
            else:
                target_obs = self.latest_obstacle_data # ì—†ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„°ë¼ë„
        else:
            # í‰ìƒì‹œ -> ê¸°ì¡´ ì¥ì• ë¬¼ ë°ì´í„° ì‚¬ìš©
            target_obs = self.latest_obstacle_data

        # ì„ íƒëœ ë°ì´í„°ë¡œ íŠ¹ì§• ë²¡í„° ìƒì„±
        if target_obs and target_obs.detected:
             # ê±°ë¦¬ ì •ê·œí™”
             d = min(target_obs.distance, self.params.R_OBJ_M) / self.params.R_OBJ_M
             # ê°ë„
             ang = np.deg2rad(target_obs.angle)
             #  vx, vyë¥¼ 0.5ë¡œ ì„¤ì • (ì •ì§€í•œ ë¬¼ì²´ë¡œ ê°€ì •í•˜ë˜ ì¡´ì¬ê° ë¶€ê°)
             obj_feats.extend([d, np.cos(ang), np.sin(ang), 0.5, 0.5]) 
        
        # íŒ¨ë”© ì±„ìš°ê¸° (ê¸°ì¡´ ë™ì¼)
        while len(obj_feats) < 15:
            obj_feats.extend([1.0, 0.0, 0.0, 0.0, 1.0])


        # 3. Lidar (64)
        lidar_feats = np.clip(self.latest_scan_data / self.params.R_RAY_M, 0.0, 1.0)
        # Danger Scalar (2ê°œ: í˜„ì¬ ìœ„í—˜ë„, ì£¼ë³€ ìœ„í—˜ë„)
        danger_scalar = np.zeros(2, dtype=np.float32)
        # Danger Lidar (16ê°œ)
        danger_lidar = np.zeros(16, dtype=np.float32)
        # ìµœì¢… ê²°í•© (ì´ 100ì°¨ì›)
        return np.concatenate([goal_feats,      # 3
                               obj_feats,       # 15
                               lidar_feats,     # 64
                               danger_scalar,   # 2
                               danger_lidar     # 16
                               ], dtype=np.float32)
    
    def main_loop(self):
        twist = Twist()
        
        # ------------------------------------------------------------------
        # [1] ì „ì—­ ìƒíƒœ ì „ì´ ì²´í¬ (ì–´ë–¤ ìƒíƒœì—ì„œë“  ì‚¬ëŒ ê°ì§€ë˜ë©´ ë‚©ì¹˜)
        # ------------------------------------------------------------------
        if self.current_state != State.PPO_HUMAN_AVOID:
            # ì½œë°±ì—ì„œ ì—…ë°ì´íŠ¸ëœ íƒ€ì´ë¨¸ë¥¼ í™•ì¸
            if self.human_detect_timer >= self.params.HUMAN_CONFIRM_TIME:
                self.get_logger().warn("ğŸš¨ HUMAN DETECTED! Switching to PPO.")
                self.current_state = State.PPO_HUMAN_AVOID
                self.human_detect_timer = 0
                self.human_clear_timer = 0
    
        # --- ìƒíƒœ ë¨¸ì‹  ---
        # ì§€ë„ ì˜¬ ë•Œê¹Œì§€ ì •ì§€
        if self.current_state == State.WAITING_FOR_MAP:
            pass
            
        elif self.current_state == State.PLANNING:
            # ê²½ë¡œ ìƒì„± ì‹œë„
            success = self.generate_path_from_map()
            if success:
                self.planning_fail_count = 0
                self.current_state = State.EXECUTING
                self.steps_after_planning = 0
                self.wp_stuck_timer = 0
                self.last_wp_idx = -1
                self.get_logger().info(f">>> Timer RESET. Starting from WP {self.wp_idx}")
            else:
                self.planning_fail_count += 1
                if self.planning_fail_count >= 2:
                    # [2ë‹¨ê³„] ë‘ ë²ˆ ì—°ì† ì‹¤íŒ¨ -> ê°•ë ¥ í›„ì§„ (Strong Backup)
                    self.get_logger().error("Wiggling failed! Force LONG BACKUP (4s)...")
                    self.current_state = State.BACKING_UP
                    self.backup_timer = 40
                    self.planning_fail_count = 0 
                    self.get_logger().warn("Planning failed! Force Wiggling (2s)...")
                else:
                    # [1ë‹¨ê³„] ì²« ì‹¤íŒ¨ -> ì œìë¦¬ ë¹„ë¹„ê¸° (Wiggle)
                    self.get_logger().warn("Planning failed! Attempting Wiggle (2s)...")
                    self.current_state = State.WIGGLING
                    self.backup_timer = 20
                
        elif self.current_state == State.EXECUTING:
            # 1. í˜„ì¬ ê²½ë¡œ ì™„ë£Œ ì²´í¬ -> [ìˆ˜ì •] ì¬ê³„íš(Re-planning) ì‹œë„
            if self.wp_idx >= len(self.global_path):
                self.get_logger().info("Current path finished. Checking for new areas...")
                # ë°”ë¡œ ë©ˆì¶”ì§€ ë§ê³ , PLANNING ìƒíƒœë¡œ ëŒì•„ê°€ì„œ ìƒˆ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
                self.current_state = State.PLANNING 
                self.cmd_vel_publisher.publish(Twist())# ê³„ì‚°í•˜ëŠ” ë™ì•ˆ ì ê¹ ì •ì§€
                return
            
            self.steps_after_planning += 1

            # ---------------------------------------------------------
            # 1. ë°©ë¬¸ ê¸°ë¡ (ë°œìêµ­) ë‚¨ê¸°ê¸°
            # ---------------------------------------------------------    
            dist_from_last = np.linalg.norm(self.current_pose_xy - self.last_record_pos)
            if dist_from_last > 0.5:
                self.visited_history.append(self.current_pose_xy.copy())
                self.last_record_pos = self.current_pose_xy.copy()
            # ---------------------------------------------------------
            # 2. Lidar Guard (ì¶©ëŒ ë°©ì§€ & í›„ì§„)
            # ---------------------------------------------------------
                
            if self.steps_after_planning > 20:
                # ì¢ì€ ê°ì‹œ (ì •ë©´)
                narrow_indices = range(30, 35)
                narrow_dist = np.min(self.latest_scan_data[narrow_indices]) if len(self.latest_scan_data) > 0 else 99.9
                # ë„“ì€ ê°ì‹œ (ì¸¡ë©´)
                wide_indices = range(5, 60)  
                wide_dist = np.min(self.latest_scan_data[wide_indices]) if len(self.latest_scan_data) > 0 else 99.9

                #  ê¸´ê¸‰ ì¶©ëŒ ë°©ì§€ (Emergency) 
                # ì½”ì•(0.5m)ì— ìˆê±°ë‚˜ ì˜†ì— ë¼ì¼ ê²ƒ ê°™ìœ¼ë©´ ë¬´ì¡°ê±´ í›„ì§„!
                if narrow_dist < 0.15 or wide_dist < 0.20:
                    self.current_state = State.BACKING_UP
                    self.backup_timer = 20
                    return
                
                # [ì¥ì• ë¬¼ ê°ì§€ Re-planning ê±°ë¦¬ 1.2m]
                SAFE_DIST_THRESHOLD = 1.2 
                if narrow_dist < SAFE_DIST_THRESHOLD:
                    self.get_logger().warn(f"Obstacle detected ahead ({narrow_dist:.2f}m)! STOP & REPLAN.")
                    self.cmd_vel_publisher.publish(Twist()) # ì •ì§€
                    # 2. í˜„ì¬ ê²½ë¡œ íê¸°
                    self.global_path = []
                    # 3. ì¦‰ì‹œ ê³„íš ìƒíƒœë¡œ ì „í™˜ (SLAMì´ ì§€ë„ë¥¼ ì—…ë°ì´íŠ¸í–ˆì„ ê²ƒì´ë¼ ê°€ì •)
                    self.current_state = State.PLANNING
                    # 4. ë¬´ì  ì‹œê°„ ì´ˆê¸°í™” (ì¬ê³„íš ì§í›„ ë°”ë¡œ ë˜ ê°ì§€ë˜ëŠ” ê²ƒ ë°©ì§€
                    self.steps_after_planning = 0
                    return
            # =========================================================
            # 4. [ì—…ê·¸ë ˆì´ë“œ] ì£¼í–‰ ë¡œì§ (ë¹™ê¸€ë¹™ê¸€ ë°©ì§€ & ì½”ë„ˆ ê°ì†)
            # =========================================================
            
            # (1) Look Ahead 
            look_dist = 1
            look_ahead = min(self.wp_idx + look_dist, len(self.global_path) - 1)
            target = self.global_path[look_ahead]
            curr_x, curr_y = self.current_pose_xy

            # (2) ì›¨ì´í¬ì¸íŠ¸ ê³„ì‚° ë° ìŠ¤í‚µ íŒì •
            real_target = self.global_path[self.wp_idx]
            dx = real_target[0] - curr_x
            dy = real_target[1] - curr_y
            dist = np.hypot(dx, dy)
            # ëª©í‘œì™€ì˜ ê°ë„ ì°¨ì´ ê³„ì‚° (ë“± ë’¤ì— ìˆëŠ”ì§€ í™•ì¸ìš©)
            target_angle = np.arctan2(dy, dx)
            angle_diff = target_angle - self.current_pose_yaw
            while angle_diff > np.pi: angle_diff -= 2*np.pi
            while angle_diff < -np.pi: angle_diff += 2*np.pi

            # ë„ë‹¬ íŒì •
            arrival_threshold = 0.5 

            if dist < arrival_threshold:
                self.wp_idx += 1
                return
            # ë“± ë’¤ ìŠ¤í‚µ (Behind Checkook_dis) 
            if dist < 1.0 and abs(angle_diff) > 2.0:
                self.wp_idx += 1
                return
            # (3) ì œì–´ìš© ê°ë„ ê³„ì‚° (Look Ahead íƒ€ê²Ÿ ê¸°ì¤€)
            dx = target[0] - curr_x
            dy = target[1] - curr_y
            desired_yaw = np.arctan2(dy, dx)
            yaw_err = desired_yaw - self.current_pose_yaw
            while yaw_err > np.pi: yaw_err -= 2*np.pi
            while yaw_err < -np.pi: yaw_err += 2*np.pi
            # (4) ì œì–´ ë¡œì§ (ì†ë„ ì¡°ì ˆ)
            if abs(yaw_err) < 0.05:
                target_ang = 0.0
            else:
                target_ang = np.clip(yaw_err * 1.5, -2.0, 2.0)

            # ì „ì§„: 
            #     ã„·ì ì½”ë„ˆì—ì„œëŠ” ì¡°ê¸ˆë§Œ ë¹„ìŠ¤ë“¬íˆ ê°€ë„ ë²½ì„ ê¸ê¸° ë•Œë¬¸ì— ì„¸ë°€íˆ ì¡°ì •
            if abs(yaw_err) > 0.4:  
                target_lin = 0.0 
            else:
                # ê°ë„ê°€ ì™„ë²½í•˜ê²Œ ë§ìœ¼ë©´ ì¶œë°œí•˜ë˜,
                # ì•„ì§ ê±°ë¦¬ê°€ ë©€ë©´ ë¹ ë¥´ê²Œ(0.8), ê°€ê¹Œìš°ë©´ ì²œì²œíˆ(0.2)
                target_lin = 0.6 if dist > 0.5 else 0.2
            # (C) í•„í„°: ì†ë„ì™€ íšŒì „ ê°’ì— ëŒ€í•œ ë°˜ì‘ì†ë„. ê°’ì´ ë‚®ì„ìˆ˜ë¡ ë°˜ì‘ë„ ë‚®ìŒ.
            alpha_lin = 0.1 
            alpha_ang = 0.4 # íšŒì „ ë°˜ì‘ ì†ë„ 

            self.current_linear_val = (target_lin * alpha_lin) + (self.current_linear_val * (1 - alpha_lin))
            self.current_angular_val = (target_ang * alpha_ang) + (self.current_angular_val * (1 - alpha_ang))
            if abs(self.current_angular_val) < 0.01: self.current_angular_val = 0.0
            
            twist.linear.x = float(self.current_linear_val)
            twist.angular.z = float(self.current_angular_val)

            # =========================================================
            #  5. ìŠ¤ë§ˆíŠ¸ ê°ì‹œê²¬ (Smart Watchdog)
            # =========================================================
            # íšŒì „ ì¤‘(ê°ë„ ì˜¤ì°¨ê°€ 0.2rad ì´ìƒ)ì¼ ë•ŒëŠ” íƒ€ì´ë¨¸ë¥¼ ë©ˆì¶¤
            is_turning = abs(yaw_err) > 0.2
            if self.wp_idx == self.last_wp_idx:
                if not is_turning: self.wp_stuck_timer += 1
                else: self.wp_stuck_timer = 0
            else:
                self.wp_stuck_timer = 0
                self.last_wp_idx = self.wp_idx

            if self.wp_stuck_timer > 100: #5ì´ˆ
                self.current_state = State.BACKING_UP
                self.backup_timer = 30
                self.wp_stuck_timer = 0
                return
        # ë””ë²„ê¹…ìš© ë¡œê·¸ (1ì´ˆì— í•œ ë²ˆë§Œ ì¶œë ¥)
            self.get_logger().info(
                f"WP: {self.wp_idx} | "
                f"CurrAngle: {np.rad2deg(self.current_pose_yaw):.1f} | "
                f"TargetAngle: {np.rad2deg(desired_yaw):.1f} | "
                f"Err: {np.rad2deg(yaw_err):.1f} | "
                f"Cmd: {self.current_angular_val:.2f}",
                throttle_duration_sec=1.0
            )
        elif self.current_state == State.BACKING_UP:
            #  ì²˜ìŒ 1.5ì´ˆëŠ” ë’¤ë¡œ ë¹ ì§„ë‹¤ (í›„ì§„)
            if self.backup_timer > 15:
                twist.linear.x = -0.5
                twist.angular.z = 0.0
                # ë‚¨ì€ 1.5ì´ˆëŠ” ì œìë¦¬ì—ì„œ ë¹„íŠ¼ë‹¤ (íšŒì „)
            else:
                twist.linear.x = 0.0
                twist.angular.z = 1.5 
            self.backup_timer -= 1
            if self.backup_timer <= 0:
                self.cmd_vel_publisher.publish(Twist())
                self.global_path = []
                self.current_state = State.PLANNING

        elif self.current_state == State.WIGGLING:
             # 2ì´ˆ ë™ì•ˆ ë’¤ë¡œ ê°€ë©´ì„œ ê°•ì œë¡œ ë•ë‹ˆë‹¤ (êµ¬ì„ íƒˆì¶œ)
            if self.backup_timer > 0:
                twist.linear.x = -0.3
                twist.angular.z = 1.5
                self.backup_timer -= 1
            else:
                twist.linear.x = 0.0
                twist.angular.z = 0.0
                self.global_path = []
                self.current_state = State.PLANNING

        elif self.current_state == State.FINISHED:
            self.get_logger().info("Mission Complete!", throttle_duration_sec=5.0)
            twist.linear.x = 0.0
            twist.angular.z = 0.0

        # =================================================================
        #  ì‚¬ëŒ íšŒí”¼ ëª¨ë“œ (PPO)
        # =================================================================
        elif self.current_state == State.PPO_HUMAN_AVOID:
             # [ì•ˆì „ ì¥ì¹˜] ì‚¬ëŒì´ ë„ˆë¬´ ê°€ê¹Œìš°ë©´(1.5m ì´ë‚´) PPOê³  ë­ê³  ì¼ë‹¨ ê¸‰ì •ì§€
            if self.latest_human_data and self.latest_human_data.distance < 1.5:
                self.get_logger().error("ğŸš¨ HUMAN TOO CLOSE! EMERGENCY STOP!", throttle_duration_sec=1.0)
                twist.linear.x = 0.0
                twist.angular.z = 0.0
                self.cmd_vel_publisher.publish(twist)
                self.action_lock_timer = 0 # ë½ ì´ˆê¸°í™”
                return # PPO ì‹¤í–‰ ìŠ¤í‚µ
            
            # 1. íƒˆì¶œ ì¡°ê±´ (3ì´ˆ ë™ì•ˆ ì‚¬ëŒ ì—†ìœ¼ë©´ ë³µê·€)
            if self.human_clear_timer >= self.params.HUMAN_CLEAR_TIME:
                self.get_logger().info("âœ… Human Clear. Re-planning path...")
                # ì•ˆì „í•´ì§€ë©´ ë‹¤ì‹œ ê²½ë¡œ ê³„íšë¶€í„° ì‹œì‘ 
                self.current_state = State.PLANNING
                self.global_path = [] 
                self.human_clear_timer = 0
                self.action_lock_timer = 0 # ë½ ì´ˆê¸°í™”
                return 

            # 2. PPO ì‹¤í–‰ (Action Locking ì ìš©)
            if self.ppo_model:
                action = 4 # ê¸°ë³¸ ì •ì§€

                # (A) ë½ì´ ê±¸ë ¤ìˆìœ¼ë©´ -> AIí•œí…Œ ë¬»ì§€ ë§ê³  ì €ì¥ëœ í–‰ë™ ë°˜ë³µ
                if self.action_lock_timer > 0:
                    action = self.locked_action
                    self.action_lock_timer -= 1
                    # self.get_logger().info(f"ğŸ”’ Locked Action: {action} (Rem: {self.action_lock_timer})")
                
                # (B) ë½ì´ ì—†ìœ¼ë©´ -> AIì—ê²Œ ë¬¼ì–´ë´„
                else:
                    obs = self.build_state_for_ppo()
                    with torch.no_grad():
                        tensor = torch.FloatTensor(obs).unsqueeze(0)
                        logits, _ = self.ppo_model(tensor)
                        action = torch.argmax(logits).item()
                    
                    # [í•µì‹¬ ë¡œì§] íšŒì „ í–‰ë™(1:ì¢Œ, 3:ìš°)ì´ ë‚˜ì˜¤ë©´ ë½ì„ ê±´ë‹¤!
                    # 1(Left), 3(Right)ì¼ ê²½ìš°ì—ë§Œ 5í”„ë ˆì„(0.5ì´ˆ) ë™ì•ˆ ìœ ì§€
                    # 0(Forward)ì´ë‚˜ 2(Back)ëŠ” ì¦‰ê° ë°˜ì‘í•´ë„ ê´œì°®ìŒ
                    if action == 1 or action == 3:
                        self.action_lock_timer = 5  # 0.1ì´ˆ * 5 = 0.5ì´ˆ ë™ì•ˆ ìœ ì§€
                        self.locked_action = action
                        self.get_logger().warn(f"ğŸ¤– PPO Turn START! Action {action} Locked for 0.5s")
                    
                    # í›„ì§„(2)ì˜ ê²½ìš°ë„ ì¡°ê¸ˆ ê¸¸ê²Œ ì¡ì•„ì£¼ë©´ ì¢‹ìŒ
                    elif action == 2:
                        self.action_lock_timer = 3  # 0.3ì´ˆ
                        self.locked_action = action

                # ì•¡ì…˜ ì‹¤í–‰
                lx, az = self.params.ACTION_MAP[action]
                twist.linear.x = lx
                twist.angular.z = az
                
            else:
                twist.linear.x = 0.0
                twist.angular.z = 0.0
        
        self.cmd_vel_publisher.publish(twist)

    # ê²½ë¡œ ë°œí–‰ í•¨ìˆ˜
    def publish_path(self):
        if not self.global_path: return
        path_msg = Path()
        path_msg.header.frame_id = "map"
        path_msg.header.stamp = self.get_clock().now().to_msg()
        for pt in self.global_path:
            pose = PoseStamped()
            pose.header = path_msg.header
            pose.pose.position.x = float(pt[0])
            pose.pose.position.y = float(pt[1])
            pose.pose.position.z = 0.2
            path_msg.poses.append(pose)
        self.path_publisher.publish(path_msg)

def main(args=None):
    rclpy.init(args=args)
    node = AiControllerNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()